{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">7. Clasificación</h1>\n",
    "<h2 style=\"text-align: center;\">Redes neuronales artificiales</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elaborado por el Dr. Carlos Francisco Méndez para la asignatura de Introducción a la Ciencia de Datos de la Licenciatura en Ciencias Genómicas\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Entrenar un modelo de red neuronal artificial profunda para resolver una tarea de clasificación multiclase usando PyTorch.\n",
    "\n",
    "Notebook adaptado de la [Capacitación oficial de PyTorch.](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "## Descripción de la tarea\n",
    "\n",
    "En este taller vamos a user el conjunto de datos FashionMNIST. El modelo debe clasificar imágenes de elementos de vestimenta en una de 10 posibles categorías:\n",
    "\n",
    "0. T-shirt/top\n",
    "1. Trouser\n",
    "2. Pullover\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot        \n",
    "    \n",
    "Ejemplos de entrada:\n",
    "<img \n",
    "    style=\"display: block; \n",
    "           margin-left: auto;\n",
    "           margin-right: auto;\n",
    "           width: 50%;\"\n",
    "    src=\"fashion-mnist-sprite.png\" \n",
    "    alt=\"FashionMNIST\">\n",
    "</img>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmendezc/miniconda3/envs/gitlab-deep-learning-for-bionlp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y creación de conjuntos de entrenamiento y prueba\n",
    "\n",
    "Usaremos dos objetos de PyTorch para manejo de datos:\n",
    "* Dataset: permite almacenar conjuntos de datos en forma de `Ejemplo - Etiqueta`.\n",
    "* DataLoader: permite iterar a través del conjunto de datos.\n",
    "\n",
    "El módulo `torchvision.datasets` contiene objetos de la clase `Dataset` para acceder a diversos conjuntos de datos disponibles para uso libre. \n",
    "\n",
    "Usaremos el conjunto de datos `FashionMNIS`. El argumento `transform` permite transformar los datos en tensores con el parámetro ToTensor() y el argumento `download=True` indica que el dataset debe ser descargado.\n",
    "\n",
    "Dividimos el conjunto de datos en dos subconjuntos. Unos será usado para el entrenamiento de la red (`train_data`) y el otro para evaluarla (`test_data`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 26421880/26421880 [00:20<00:00, 1318903.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 29515/29515 [00:00<00:00, 96686.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 4422102/4422102 [00:20<00:00, 216491.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 5148/5148 [00:00<00:00, 10641.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de `DataLoader`\n",
    "\n",
    "Definimos un tamaño de lote para que la red ajuste sus pesos cada 64 ejemplos (`batch_size = 64`).\n",
    "\n",
    "Creamos dos objetos `DataLoader` para iterar ambos conjuntos de datos por lotes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observación del DataLoader\n",
    "\n",
    "Vamos a iterar sobre el DataLoader de prueba (`test_dataloader`) para ver observar la dimesionalidad del primer lote y su categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalidad de datos X [TamañoLote, CanalImag, LargoImag, AnchoImag]: torch.Size([64, 1, 28, 28])\n",
      "Dimensionalidad de categorías y: torch.Size([64]), tipo de categorías: torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    print(f\"Dimensionalidad de datos X [TamañoLote, CanalImag, LargoImag, AnchoImag]: {X.shape}\")\n",
    "    print(f\"Dimensionalidad de categorías y: {y.shape}, tipo de categorías: {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de la red neuronal\n",
    "\n",
    "### Definición de `device` para entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device a utulizar: cpu\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Device a utulizar: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de arquitectura de la red neuronal\n",
    "\n",
    "Creamos la clase `RedNeuronal` a partir de la clase base [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Esta clase será definida de acuerdo a la arquitectura de red que deseamos entrenar.\n",
    "\n",
    "Debemos definir:\n",
    "- Capas\n",
    "- Nodos por capa\n",
    "- Función de activación\n",
    "- Procesamiento hacia adelante de la red (`forward`)\n",
    "\n",
    "Al final indicamos que la red debe crearse en el `device` definido anteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedNeuronal(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define modelo\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = RedNeuronal().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de función de pérdida y optimizador\n",
    "\n",
    "Para que la red neuronal aprenda debemos utilizar una [función de pérdida o loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) que mida las predicciones de la red y un [optimizador](https://pytorch.org/docs/stable/optim.html) que ajuste los pesos de la red neuronal para intenter predecir cada vez mejor, esto es, diminuir el valor de la función de pérdida.\n",
    "\n",
    "La función de pérdida más recomendada para resolver tareas de clasificación multiclase es la Entropía crusada (`CrossEntropyLoss`).\n",
    "\n",
    "El optimizador más sencillo es uno basado de el algortimo de Descenso por gradiente estocástico (`SGD`). La tasa de aprendizaje (learning rate o `lr`) será definida como 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de método de entrenamiento (`train`)\n",
    "\n",
    "Esto incluye procesar los datos del `dataloader` lote por lote \"hacia delante\" y calcular el error de predicción de la red, esto es, el valor de la función de pérdida. Luego debemos propagar el error de predicción \"hacia atrás\" de la red para ajustar los pesos de los nodos. En cada iteración, la red ajustará los pesos para predecir cada vez mejor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Valor de función de pérdida: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de método de prueba (`test`)\n",
    "\n",
    "Esto incluye procesar los datos de prueba lote por lote, esto es, hacer que la red previamente entrenada realice predicciones sobre estos datos y acumular tanto el error (valor de la función de perdida) como los aciertos de la red (valor de exactitud o `Accuracy`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Fase de prueba: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de la red neuronal\n",
    "\n",
    "Ejecutamos los métodos de entrenamiento (`train`) y prueba (`test`) por un número de épocas (veces que la red entrena usando todos los datos disponibles).\n",
    "\n",
    "El `train` imprimirá el valor de pérdida por cada 100 lotes. El método `test` imprimirá el valro de pérdida y la exactitud de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Valor de función de pérdida: 2.295148  [   64/60000]\n",
      "Valor de función de pérdida: 2.188300  [ 6464/60000]\n",
      "Valor de función de pérdida: 1.943067  [12864/60000]\n",
      "Valor de función de pérdida: 1.758663  [19264/60000]\n",
      "Valor de función de pérdida: 1.389056  [25664/60000]\n",
      "Valor de función de pérdida: 1.259039  [32064/60000]\n",
      "Valor de función de pérdida: 1.156245  [38464/60000]\n",
      "Valor de función de pérdida: 1.035730  [44864/60000]\n",
      "Valor de función de pérdida: 0.984882  [51264/60000]\n",
      "Valor de función de pérdida: 0.898710  [57664/60000]\n",
      "Fase de prueba: \n",
      " Accuracy: 69.8%, Avg loss: 0.893073 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Valor de función de pérdida: 0.910444  [   64/60000]\n",
      "Valor de función de pérdida: 0.952670  [ 6464/60000]\n",
      "Valor de función de pérdida: 0.704896  [12864/60000]\n",
      "Valor de función de pérdida: 0.893996  [19264/60000]\n",
      "Valor de función de pérdida: 0.732190  [25664/60000]\n",
      "Valor de función de pérdida: 0.739940  [32064/60000]\n",
      "Valor de función de pérdida: 0.769769  [38464/60000]\n",
      "Valor de función de pérdida: 0.754076  [44864/60000]\n",
      "Valor de función de pérdida: 0.718175  [51264/60000]\n",
      "Valor de función de pérdida: 0.716159  [57664/60000]\n",
      "Fase de prueba: \n",
      " Accuracy: 75.6%, Avg loss: 0.692254 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Valor de función de pérdida: 0.654283  [   64/60000]\n",
      "Valor de función de pérdida: 0.760616  [ 6464/60000]\n",
      "Valor de función de pérdida: 0.526863  [12864/60000]\n",
      "Valor de función de pérdida: 0.760682  [19264/60000]\n",
      "Valor de función de pérdida: 0.625714  [25664/60000]\n",
      "Valor de función de pérdida: 0.636935  [32064/60000]\n",
      "Valor de función de pérdida: 0.652481  [38464/60000]\n",
      "Valor de función de pérdida: 0.697624  [44864/60000]\n",
      "Valor de función de pérdida: 0.648864  [51264/60000]\n",
      "Valor de función de pérdida: 0.636851  [57664/60000]\n",
      "Fase de prueba: \n",
      " Accuracy: 78.4%, Avg loss: 0.615343 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar modelo entrenado\n",
    "\n",
    "Para guardar nuestro modelo entrenado, almacenamos en un archivo los pesos ajustados finales de la red neuronal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardamos modelo entrenado en model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Guardamos modelo entrenado en model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase de inferencia\n",
    "\n",
    "\n",
    "### Cargar modelo entrenado\n",
    "\n",
    "Para usar nuestro modelo entrenado, creamos una instancia de la red neuronal y le cargamos los pesos almacenados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RedNeuronal().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usar modelo entrenado\n",
    "\n",
    "Predecir con el modelo entrenado la categoría de nuevos datos. Como ejemplo, usemos la imagen 919 del conjunto de datos de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría: Trouser\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdI0lEQVR4nO3df2xV9f3H8ddtoZdSy50Ve++trU2noIslJIKAxB+FjcYmIypqUBMDmTM6gYRUY8b4w2bJqHGR8Ecny4xByGSyP9SZQIRu2DJlLEBwEDQER5GqvavU0ltKuaXt+f5BvN9cyw8/x3v7vrd9PpKTcM89L87H0yOve3ru/dyA53meAAAwkGc9AADA+EUJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwMwE6wF81/DwsL766isVFxcrEAhYDwcA4MjzPPX29qqsrEx5eVe+1sm6Evrqq69UUVFhPQwAwA/U3t6u8vLyK26TdSVUXFxsPQRkme3btztnBgcHfe1rYGDAORMMBp0zp06dGpX9lJaWOmckqa+vzzmTn5/vnLnaq+RLeeSRR5wzsPF9/j3PWAm9+uqr+v3vf6+Ojg7ddttt2rBhg+6+++6r5vgVHL6rqKjIOeO3hCZMcP9fYtKkSc6ZwsLCUdmPn2MnXfx1iqvRKiHkju/z73lGzoBt27Zp9erVWrt2rQ4dOqS7775bdXV1vl79AQDGroyU0Pr16/Xkk0/ql7/8pX7yk59ow4YNqqio0MaNGzOxOwBAjkp7CQ0MDOjgwYOqra1NWV9bW6u9e/eO2D6RSCgej6csAIDxIe0ldPr0aQ0NDSkcDqesD4fDisViI7ZvbGxUKBRKLrwzDgDGj4zdFfzuDSnP8y55k2rNmjXq6elJLu3t7ZkaEgAgy6T93XFTp05Vfn7+iKuezs7OEVdH0sW3nfp56ykAIPel/UqooKBAs2bNUnNzc8r65uZmzZ8/P927AwDksIx8Tqi+vl5PPPGEZs+erTvvvFN/+tOfdOrUKT3zzDOZ2B0AIEdlpISWLl2qrq4u/fa3v1VHR4eqq6u1Y8cOVVZWZmJ3AIAcFfD8fDQ6g+LxuEKhkPUwkCFTpkxxzvz3v/91znR2djpn/Jo8ebJzxs9MAefPn3fODA0NOWck6dy5c84ZP/d2/fycfvrTnzpnYKOnp+eq/88zZwYAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzGZlFG7icSZMmOWf8zLE7YYK/U3tgYGBUMt3d3c6Z/Px854yfCWMlf8f85MmTzpn+/n7nDMYWroQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGaYRRuj6qGHHnLOlJSUOGfa29udM5K/2bfz8txfyyUSiVHZj59ZyyV/xyEUCjlnotGoc2bWrFnOmYMHDzpnMDq4EgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGCUwxqp588knnTEdHh3Pm66+/ds5IUmlpqXNmcHDQOVNeXu6cOXfunHNmeHjYOSNJ58+fd874OQ7hcNg5M2fOHOcME5hmL66EAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmGECU4yqW265xTnjZ/LJwsJC54wkTZw40TmTl+f+Wq6vr885U1BQ4Jzxq6enZ1QyfiZYLSsrc84ge3ElBAAwQwkBAMykvYQaGhoUCARSlkgkku7dAADGgIzcE7rtttv097//Pfk4Pz8/E7sBAOS4jJTQhAkTuPoBAFxVRu4JHT9+XGVlZaqqqtKjjz6qEydOXHbbRCKheDyesgAAxoe0l9DcuXO1ZcsW7dy5U6+99ppisZjmz5+vrq6uS27f2NioUCiUXCoqKtI9JABAlkp7CdXV1emhhx7SjBkz9LOf/Uzbt2+XJG3evPmS269Zs0Y9PT3Jpb29Pd1DAgBkqYx/WLWoqEgzZszQ8ePHL/l8MBhUMBjM9DAAAFko458TSiQS+vTTTxWNRjO9KwBAjkl7CT3//PNqbW1VW1ub/v3vf+vhhx9WPB7XsmXL0r0rAECOS/uv47744gs99thjOn36tK6//nrNmzdP+/btU2VlZbp3BQDIcWkvobfeeivdfyWylJ9fsU6Y4H7KdXZ2OmdKS0udM5LkeZ5zZmBgwDnj512g58+fd86cPXvWOSP5m8jVz8/Wz39TIpFwziB7MXccAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAMxn/UjuMXeFw2DnT19eXgZGMFAgEfOX6+/udM9ddd51z5sCBA86Z6upq50xRUZFzRpJ6e3udM3l57q9pBwcHnTN+Jj1F9uJKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghlm04dstt9zinPEza/JozbwtSZ7nOWei0ahz5uabb3bOHDp0yDkzffp054wknTp1yjlz4cIF58zQ0JBzJpFIOGeQvbgSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYJTOHbrbfe6pzxMxlpUVGRc8bPRKmSFA6HnTOnT5/2tS9X+/btc87MnDnT176Gh4edM8Fg0DnjZ8LYgYEB5wyyF1dCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzDCBKXy7+eabnTM9PT3OmYKCAueM3wlMy8rKnDNvvPGGr325ev31150zzzzzjK995efn+8q58vNzGhoaysBIYIUrIQCAGUoIAGDGuYT27NmjxYsXq6ysTIFAQO+++27K857nqaGhQWVlZSosLFRNTY2OHj2arvECAMYQ5xLq6+vTzJkz1dTUdMnnX375Za1fv15NTU3av3+/IpGIFi1apN7e3h88WADA2OL8xoS6ujrV1dVd8jnP87RhwwatXbtWS5YskSRt3rxZ4XBYW7du1dNPP/3DRgsAGFPSek+ora1NsVhMtbW1yXXBYFD33nuv9u7de8lMIpFQPB5PWQAA40NaSygWi0mSwuFwyvpwOJx87rsaGxsVCoWSS0VFRTqHBADIYhl5d1wgEEh57HneiHXfWrNmjXp6epJLe3t7JoYEAMhCaf2waiQSkXTxiigajSbXd3Z2jrg6+lYwGFQwGEznMAAAOSKtV0JVVVWKRCJqbm5OrhsYGFBra6vmz5+fzl0BAMYA5yuhs2fP6rPPPks+bmtr08cff6ySkhLdeOONWr16tdatW6dp06Zp2rRpWrdunSZPnqzHH388rQMHAOQ+5xI6cOCAFixYkHxcX18vSVq2bJneeOMNvfDCC+rv79ezzz6r7u5uzZ07V7t27VJxcXH6Rg0AGBOcS6impkae5132+UAgoIaGBjU0NPyQcSEHTJkyxTnT39/vnLnS+XY5Eyb4u905ceJE58yGDRt87cvVgQMHnDPDw8O+9pWX5/6bej+TkQ4MDDhnmMB0bGHuOACAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAmbR+syrGlwsXLjhn+vr6nDN+ZtGePHmyc0a6+K3Ark6cOOFrX6Ohq6vLVy4QCDhnuru7nTNTp051zkyaNMk5g+zFlRAAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzTGAK37755hvnzMSJEzMwkpGuueYaX7n3338/zSOx5WdCVkkaHh52znz99dfOmWuvvdY5k5+f75xB9uJKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBkmMIVvvb29zhk/E1ZOmOB+mt50003OGUl67rnnfOVc5eW5v/7zM6loW1ubc0aSbrjhBufM6dOnnTN+frbl5eXOGWQvroQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYYQJT+DYwMOCcmTRpknPmmmuucc74mSBUkj755BNfOVf5+fnOGT8TmB49etQ5I0lVVVXOmXg87py5/vrrnTPd3d3OGWQvroQAAGYoIQCAGecS2rNnjxYvXqyysjIFAgG9++67Kc8vX75cgUAgZZk3b166xgsAGEOcS6ivr08zZ85UU1PTZbe577771NHRkVx27NjxgwYJABibnN+YUFdXp7q6uituEwwGFYlEfA8KADA+ZOSeUEtLi0pLSzV9+nQ99dRT6uzsvOy2iURC8Xg8ZQEAjA9pL6G6ujq9+eab2r17t1555RXt379fCxcuVCKRuOT2jY2NCoVCyaWioiLdQwIAZKm0f05o6dKlyT9XV1dr9uzZqqys1Pbt27VkyZIR269Zs0b19fXJx/F4nCICgHEi4x9WjUajqqys1PHjxy/5fDAYVDAYzPQwAABZKOOfE+rq6lJ7e7ui0WimdwUAyDHOV0Jnz57VZ599lnzc1tamjz/+WCUlJSopKVFDQ4MeeughRaNRnTx5Ur/5zW80depUPfjgg2kdOAAg9zmX0IEDB7RgwYLk42/v5yxbtkwbN27UkSNHtGXLFp05c0bRaFQLFizQtm3bVFxcnL5RAwDGBOcSqqmpked5l31+586dP2hAyB2HDx92zsyZM8c54+ee4eXuQV5NLBbzlXPlZzJSP7Zv3+4rt2rVKudMUVGRcyYcDjtnurq6nDPIXswdBwAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwk/FvVsXY9de//tU584tf/MI5MzQ05JyZMmWKc0aSFi5c6JzZtWuXcyYQCDhn/Dh27Jiv3BdffOGc8TMzeF6e++tgvz9bZCeuhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJhhAlP45mdi0QsXLjhnrrnmGufM4OCgc0aSnnjiCeeMnwlM/Y7P1enTp33lwuGwc6aystI54+dne/78eecMshdXQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMwwgSlGlZ8JKwsLC50zfie5nDNnjq/cWDNp0iTnzO233+6cKSgocM74OR+QvbgSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYJTDGqPvroI+fM448/7pzp6upyzkjS2bNnfeXGms8//9w5U1JS4pzxM4FpXh6vnccSfpoAADOUEADAjFMJNTY26o477lBxcbFKS0v1wAMP6NixYynbeJ6nhoYGlZWVqbCwUDU1NTp69GhaBw0AGBucSqi1tVUrVqzQvn371NzcrMHBQdXW1qqvry+5zcsvv6z169erqalJ+/fvVyQS0aJFi9Tb25v2wQMAcpvTGxPef//9lMebNm1SaWmpDh48qHvuuUee52nDhg1au3atlixZIknavHmzwuGwtm7dqqeffjp9IwcA5LwfdE+op6dH0v+/K6atrU2xWEy1tbXJbYLBoO69917t3bv3kn9HIpFQPB5PWQAA44PvEvI8T/X19brrrrtUXV0tSYrFYpKkcDicsm04HE4+912NjY0KhULJpaKiwu+QAAA5xncJrVy5UocPH9Zf/vKXEc8FAoGUx57njVj3rTVr1qinpye5tLe3+x0SACDH+Pqw6qpVq/Tee+9pz549Ki8vT66PRCKSLl4RRaPR5PrOzs4RV0ffCgaDCgaDfoYBAMhxTldCnudp5cqVevvtt7V7925VVVWlPF9VVaVIJKLm5ubkuoGBAbW2tmr+/PnpGTEAYMxwuhJasWKFtm7dqr/97W8qLi5O3ucJhUIqLCxUIBDQ6tWrtW7dOk2bNk3Tpk3TunXrNHnyZF9TrwAAxjanEtq4caMkqaamJmX9pk2btHz5cknSCy+8oP7+fj377LPq7u7W3LlztWvXLhUXF6dlwACAscOphDzPu+o2gUBADQ0Namho8DsmjGFNTU3OmYcfftg5Mzw87JyRpB/96EfOmR//+MfOmRMnTjhnRpOfD5f7eaGZn5/vnOnu7nbOIHsxdxwAwAwlBAAwQwkBAMxQQgAAM5QQAMAMJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwIyvb1YF/Pryyy+dM2fOnHHOFBUVOWckqaCgwDkzZ84c50y2z6KdSCScM9dee61zxs/x5puYxxauhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJhhAlP4FggEnDOe5zlndu3a5Zx5+OGHnTOSNDAw4Jy5//77nTNvvfWWc2Y09fX1OWfy8txf0/rJ+DnvkL24EgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGCUzhm5/JJ4eGhpwzO3bscM488sgjzhlJ6u/vd86Ul5f72lc26+npcc4UFBQ4Z7755hvnzHXXXeecQfbiSggAYIYSAgCYoYQAAGYoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZJjCFb8PDw6Oyn48++sg58+WXX/raVygUcs5EIhHnzMyZM50z//nPf5wzfsXjcefM5MmTnTODg4POme7ubucMshdXQgAAM5QQAMCMUwk1NjbqjjvuUHFxsUpLS/XAAw/o2LFjKdssX75cgUAgZZk3b15aBw0AGBucSqi1tVUrVqzQvn371NzcrMHBQdXW1qqvry9lu/vuu08dHR3Jxc+XkgEAxj6nNya8//77KY83bdqk0tJSHTx4UPfcc09yfTAY9HWzFgAwvvyge0LffgVwSUlJyvqWlhaVlpZq+vTpeuqpp9TZ2XnZvyORSCgej6csAIDxwXcJeZ6n+vp63XXXXaqurk6ur6ur05tvvqndu3frlVde0f79+7Vw4UIlEolL/j2NjY0KhULJpaKiwu+QAAA5xvfnhFauXKnDhw/rww8/TFm/dOnS5J+rq6s1e/ZsVVZWavv27VqyZMmIv2fNmjWqr69PPo7H4xQRAIwTvkpo1apVeu+997Rnzx6Vl5dfcdtoNKrKykodP378ks8Hg0EFg0E/wwAA5DinEvI8T6tWrdI777yjlpYWVVVVXTXT1dWl9vZ2RaNR34MEAIxNTveEVqxYoT//+c/aunWriouLFYvFFIvF1N/fL0k6e/asnn/+ef3rX//SyZMn1dLSosWLF2vq1Kl68MEHM/IfAADIXU5XQhs3bpQk1dTUpKzftGmTli9frvz8fB05ckRbtmzRmTNnFI1GtWDBAm3btk3FxcVpGzQAYGxw/nXclRQWFmrnzp0/aEAAgPGDWbTh29VelFg6deqUr9zixYudM35mgl60aJFzZjRn0fbzm4vCwsIMjGSkcDg8KvvB6GACUwCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCYoYQAAGaYwBRj0u9+9ztfuVgs5pwZGBhwzrS0tDhnRtO2bducM//73/+cM2fOnHHO/OMf/3DOIHtxJQQAMEMJAQDMUEIAADOUEADADCUEADBDCQEAzFBCAAAzlBAAwAwlBAAwQwkBAMxQQgAAM1k3d5znedZDwBgwNDTkK3f+/HnnjJ+54/yOb7RcuHDBOePn2PnJDA4OOmdg4/v8ex7wsuxf/S+++EIVFRXWwwAA/EDt7e0qLy+/4jZZV0LDw8P66quvVFxcrEAgkPJcPB5XRUWF2tvbNWXKFKMR2uM4XMRxuIjjcBHH4aJsOA6e56m3t1dlZWXKy7vyXZ+s+3VcXl7eVZtzypQp4/ok+xbH4SKOw0Uch4s4DhdZH4dQKPS9tuONCQAAM5QQAMBMTpVQMBjUiy++qGAwaD0UUxyHizgOF3EcLuI4XJRrxyHr3pgAABg/cupKCAAwtlBCAAAzlBAAwAwlBAAwk1Ml9Oqrr6qqqkqTJk3SrFmz9M9//tN6SKOqoaFBgUAgZYlEItbDyrg9e/Zo8eLFKisrUyAQ0LvvvpvyvOd5amhoUFlZmQoLC1VTU6OjR4/aDDaDrnYcli9fPuL8mDdvns1gM6SxsVF33HGHiouLVVpaqgceeEDHjh1L2WY8nA/f5zjkyvmQMyW0bds2rV69WmvXrtWhQ4d09913q66uTqdOnbIe2qi67bbb1NHRkVyOHDliPaSM6+vr08yZM9XU1HTJ519++WWtX79eTU1N2r9/vyKRiBYtWqTe3t5RHmlmXe04SNJ9992Xcn7s2LFjFEeYea2trVqxYoX27dun5uZmDQ4Oqra2Vn19fcltxsP58H2Og5Qj54OXI+bMmeM988wzKetuvfVW79e//rXRiEbfiy++6M2cOdN6GKYkee+8807y8fDwsBeJRLyXXnopue78+fNeKBTy/vjHPxqMcHR89zh4nuctW7bMu//++03GY6Wzs9OT5LW2tnqeN37Ph+8eB8/LnfMhJ66EBgYGdPDgQdXW1qasr62t1d69e41GZeP48eMqKytTVVWVHn30UZ04ccJ6SKba2toUi8VSzo1gMKh777133J0bktTS0qLS0lJNnz5dTz31lDo7O62HlFE9PT2SpJKSEknj93z47nH4Vi6cDzlRQqdPn9bQ0JDC4XDK+nA4rFgsZjSq0Td37lxt2bJFO3fu1GuvvaZYLKb58+erq6vLemhmvv35j/dzQ5Lq6ur05ptvavfu3XrllVe0f/9+LVy4UIlEwnpoGeF5nurr63XXXXepurpa0vg8Hy51HKTcOR+ybhbtK/nuVzt4njdi3VhWV1eX/POMGTN055136qabbtLmzZtVX19vODJ74/3ckKSlS5cm/1xdXa3Zs2ersrJS27dv15IlSwxHlhkrV67U4cOH9eGHH454bjydD5c7DrlyPuTEldDUqVOVn58/4pVMZ2fniFc840lRUZFmzJih48ePWw/FzLfvDuTcGCkajaqysnJMnh+rVq3Se++9pw8++CDlq1/G2/lwueNwKdl6PuRECRUUFGjWrFlqbm5OWd/c3Kz58+cbjcpeIpHQp59+qmg0aj0UM1VVVYpEIinnxsDAgFpbW8f1uSFJXV1dam9vH1Pnh+d5Wrlypd5++23t3r1bVVVVKc+Pl/PhasfhUrL2fDB8U4STt956y5s4caL3+uuve5988om3evVqr6ioyDt58qT10EbNc88957W0tHgnTpzw9u3b5/385z/3iouLx/wx6O3t9Q4dOuQdOnTIk+StX7/eO3TokPf55597nud5L730khcKhby3337bO3LkiPfYY4950WjUi8fjxiNPrysdh97eXu+5557z9u7d67W1tXkffPCBd+edd3o33HDDmDoOv/rVr7xQKOS1tLR4HR0dyeXcuXPJbcbD+XC145BL50POlJDned4f/vAHr7Ky0isoKPBuv/32lLcjjgdLly71otGoN3HiRK+srMxbsmSJd/ToUethZdwHH3zgSRqxLFu2zPO8i2/LffHFF71IJOIFg0Hvnnvu8Y4cOWI76Ay40nE4d+6cV1tb611//fXexIkTvRtvvNFbtmyZd+rUKethp9Wl/vsleZs2bUpuMx7Oh6sdh1w6H/gqBwCAmZy4JwQAGJsoIQCAGUoIAGCGEgIAmKGEAABmKCEAgBlKCABghhICAJihhAAAZighAIAZSggAYIYSAgCY+T+QAs9H40E9IQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "image, label = test_data[5]\n",
    "pyplot.imshow(image[0], cmap='gray')\n",
    "print('Categoría:', classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos nuestro modelo entrenado en modo de evaluación `model.eval()` y sin ajustes de pesos: `torch.no_grad()`.\n",
    "\n",
    "Imprimimos la categoría predicha por el modelo y la categoría verdadera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categoría predicha: \"Trouser\", Categoría verdadera: \"Trouser\"\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "x, y = test_data[5][0], test_data[5][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Categoría predicha: \"{predicted}\", Categoría verdadera: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gitlab-deep-learning-for-bionlp",
   "language": "python",
   "name": "gitlab-deep-learning-for-bionlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
