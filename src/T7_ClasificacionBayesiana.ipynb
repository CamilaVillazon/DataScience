{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26TYii7Z8Dxn"
   },
   "source": [
    "# Clasificación bayesiana\n",
    "\n",
    "El siguiente notebook es explicativo, preferiblemente usar el servidor de la escuela. \n",
    "\n",
    "Utilizaremos el dataset del corpus GeniaMK para polaridad, el corpus GENIA-MK consiste en 1000 abstracts de literatura biomédica anotados con eventos de alto nivel de información que llaman metaconocimiento. Se define metaconocimiento como las diferentes formas en que la información relacionada con la interpretación puede expresarse en un texto.  Entre ellos se encuentra la dimensión polaridad que tiene como objetivo el identificar si un evento describe una situación positiva o negativa. La forma más común en que se presentan estos eventos es con el uso de la palabra no (*not o no*) aunque también considera palabras que expresan que el evento no ocurre como *fail, lack, unable, exception, without*. Algunos ejemplos:\n",
    "\n",
    "\n",
    "*   CsA was found **not** to inhibit lck gene expression, nor the activity of the lck gene product.\n",
    "\n",
    "*   In contrast, NF-kappa B p50 alone **fails** to stimulate kappa B-directed transcription, and based on prior in vitro studies, is not directly regulated by I kappa B.\n",
    "\n",
    "Entonces, existen 2 categorías posibles: positivo (el valor predeterminado) y negativo.\n",
    "El archivo “genia_lemma.txt” contiene todas las oraciones recolectadas del corpus GENIA-MK y el archivo “polarity_classes.txt” contiene la clasificación para cada oración (son archivos pareados: las líneas corresponden uno a uno entre los dos archivos). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFsmp2L2GiUt"
   },
   "source": [
    "## Naïve Bayes\n",
    "\n",
    "Naïve Bayes es uno de los algoritmos más simples y poderosos para la clasificación basado en el Teorema de Bayes con una suposición de independencia entre los predictores. Naive Bayes es fácil de construir y particularmente útil para conjuntos de datos muy grandes.\n",
    "\n",
    "Existen 3 tipos: \n",
    "*   Multinomial: clasificador ampliamente utilizado para la clasificación de documentos que mantiene el recuento de palabras frecuentes presentes en los documentos.\n",
    "*   Bernoulli: se utiliza para datos discretos, donde las características solo están en forma binaria.\n",
    "*   Gaussiano: se utiliza cuando se trata de datos continuos y se utiliza la distribución gaussiana.\n",
    "\n",
    "En este documento implementaremos el Bernoulli y el Multinomial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7fkfk5YukN0"
   },
   "source": [
    "### BernoulliNB\n",
    "\n",
    "Vamos a dividir nuestros datos en un conjunto de entrenamiento y uno para probar que tan bien entreno (70/30 respectivamente), después generamos un vectorizador con CountVectorizer()la función fit() permite entrenar el vectorizador con transform() transformamos nuestros datos a un vector binario una vez entrenado el vectorizador y fit_transform entrena devuelve la vectorización. Después de vectorizar podemos  entrenar nuestro clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qRBGPVPhyoKf"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report, make_scorer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_days</th>\n",
       "      <th>age_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pulse</th>\n",
       "      <th>bmi_clasification</th>\n",
       "      <th>pulse_clasification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>50.391781</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.967120</td>\n",
       "      <td>30</td>\n",
       "      <td>Peso normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>55.419178</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34.927679</td>\n",
       "      <td>50</td>\n",
       "      <td>Obesidad</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>51.663014</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.507805</td>\n",
       "      <td>60</td>\n",
       "      <td>Peso normal</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>48.282192</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.710479</td>\n",
       "      <td>50</td>\n",
       "      <td>Sobrepeso</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>47.873973</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.011177</td>\n",
       "      <td>40</td>\n",
       "      <td>Peso normal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>21914</td>\n",
       "      <td>60.038356</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>67.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.384676</td>\n",
       "      <td>40</td>\n",
       "      <td>Sobrepeso</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age_days   age_year  gender  height  weight  ap_hi  ap_lo  cholesterol  \\\n",
       "0   0     18393  50.391781       2     168    62.0    110     80            1   \n",
       "1   1     20228  55.419178       1     156    85.0    140     90            3   \n",
       "2   2     18857  51.663014       1     165    64.0    130     70            3   \n",
       "3   3     17623  48.282192       2     169    82.0    150    100            1   \n",
       "4   4     17474  47.873973       1     156    56.0    100     60            1   \n",
       "5   8     21914  60.038356       1     151    67.0    120     80            2   \n",
       "\n",
       "   gluc  smoke  alco  active  cardio        bmi  pulse bmi_clasification  \\\n",
       "0     1      0     0       1       0  21.967120     30       Peso normal   \n",
       "1     1      0     0       1       1  34.927679     50          Obesidad   \n",
       "2     1      0     0       0       1  23.507805     60       Peso normal   \n",
       "3     1      0     0       1       1  28.710479     50         Sobrepeso   \n",
       "4     1      0     0       0       0  23.011177     40       Peso normal   \n",
       "5     2      0     0       0       0  29.384676     40         Sobrepeso   \n",
       "\n",
       "   pulse_clasification  \n",
       "0                    2  \n",
       "1                    4  \n",
       "2                    4  \n",
       "3                    4  \n",
       "4                    3  \n",
       "5                    3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lectura de archivos de datos\n",
    "import os\n",
    "\n",
    "data = pd.read_csv(\"../data/cvd_transformed.csv\")\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar categorías de clase\n",
    "data['cardio'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61839, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar dimensionalidad de datos\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos\n",
      "['50.39178082 1 1 0 0 21.9671201814059', '55.41917808 3 1 0 0 34.9276791584484', '51.6630137 3 1 0 0 23.5078053259871', '48.28219178 1 1 0 0 28.7104793249536', '47.8739726 1 1 0 0 23.0111768573307']\n",
      "Categorias de clase\n",
      "[0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos\n",
    "# X = sólo datos de características de ejemplos\n",
    "# y = categorías de clase para cada ejemplo\n",
    "DataSetX = data.iloc[:, np.r_[2, 8:12, 14:15]]\n",
    "DataSetY = list(data.iloc[:, 13])  # all rows, label only\n",
    "\n",
    "\n",
    "DataSetX.to_csv('../data/cvd_nocardio.csv', sep=\" \", header=False, index=False)\n",
    "\n",
    "with open(os.path.join(\"../data/cvd_nocardio.csv\"), mode=\"r\") as dFile:\n",
    "    DataSetX = [line.rstrip() for line in dFile]\n",
    "\n",
    "\n",
    "print(\"Datos\")\n",
    "print(DataSetX[:5])\n",
    "print(\"Categorias de clase\")\n",
    "print(DataSetY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EfCAib0HZhEt"
   },
   "outputs": [],
   "source": [
    "#Separamos nuestros datos en training y test\n",
    "trainX, testX,trainY,testY = train_test_split(DataSetX, DataSetY, test_size = 0.30)\n",
    "#Creamos un Vectorizador\n",
    "vectorizer = CountVectorizer()\n",
    "#entrenamos nuestro vectorizador con nuestros datos de training \n",
    "#vectorizamos el test con el mismo vectorizador entrenado para que tengan las mismas dimensiones \n",
    "Xtrain = vectorizer.fit_transform(trainX)\n",
    "Xtest=vectorizer.transform(testX)\n",
    "#generamos nuestro clasificador\n",
    "clf = BernoulliNB()\n",
    "#entrenamos con nuestos modelo\n",
    "clf.fit(Xtrain, trainY)\n",
    "#predecimos nuestro dataset de test\n",
    "Ypred=clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1622068025050,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "8dV_DnjKcuDj",
    "outputId": "54552056-cc2b-4a40-efae-874a05f397aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6055950840879689\n",
      "\n",
      "Precision: 0.610520916513697\n",
      "\n",
      "Recall: 0.6055950840879689\n",
      "\n",
      "F-score: 0.6071188100494818\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[6516 4025]\n",
      " [3292 4719]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64     10541\n",
      "           1       0.54      0.59      0.56      8011\n",
      "\n",
      "    accuracy                           0.61     18552\n",
      "   macro avg       0.60      0.60      0.60     18552\n",
      "weighted avg       0.61      0.61      0.61     18552\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\n'.format(accuracy_score(Ypred,testY)))\n",
    "print('Precision: {}\\n'.format(precision_score(Ypred,testY, average='weighted')))\n",
    "print('Recall: {}\\n'.format(recall_score(Ypred,testY, average='weighted')))\n",
    "print('F-score: {}\\n'.format(f1_score(Ypred,testY, average='weighted')))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "print(str(confusion_matrix(Ypred,testY)) + '\\n')\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(Ypred,testY) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNdROeu9QSZ3"
   },
   "source": [
    "Como podemos ver nuestro clasificador no es muy bueno para la clase positiva pero eso sólo es un reflejo del desbalance de clase que tenemos.\n",
    "\n",
    "Observemos los hiperparámetros de nuestro clasificador.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1622068028761,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "1j2OLfoJgiKq",
    "outputId": "3b7df8b7-7aed-4b11-e3d6-61137b0df3de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0,\n",
       " 'binarize': 0.0,\n",
       " 'class_prior': None,\n",
       " 'fit_prior': True,\n",
       " 'force_alpha': 'warn'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_AsmGgGTZU6"
   },
   "source": [
    "Podemos buscar mejores hiperparámetros con **RandomizedSearchCV** y **GridSearchCV**\n",
    "\n",
    "**GridSearchCV**\n",
    "\n",
    "Búsqueda exhaustiva de valores de parámetros fijos mediante validación cruzada de k-folds.\n",
    "\n",
    "Los parámetros de este método son:\n",
    "- el estimador (nuestro clasificador)\n",
    "- param_grid: un diccionario con los parámetros de nuestro clasificador, en el caso de los BernoulliNB y MultinomialNB solo requiere de alpha\n",
    "- jobs: indica el número de procesos paralelos que usará, -1 significa que ejecute todos los posibles\n",
    "- cv (cross-validation) que tiene por defecto 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9654,
     "status": "ok",
     "timestamp": 1622068040841,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "iO6uRS9Lgnbz",
    "outputId": "edfd42c6-b880-42fe-c342-5a332e326f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "jobs = -1\n",
    "crossV = 5\n",
    "alpha=[]\n",
    "#generamos 100 numeros del 0 al 1 para utilizar como alphas\n",
    "for i in range(100):\n",
    "  alpha.append(i/100) \n",
    "parameters = {'alpha' : alpha}\n",
    "#generamos nuestro clasificador\n",
    "Bernoulli = BernoulliNB()\n",
    "#generamos nuestro objeto GridSearchCV con nuestro clasificador, verbouse es el numero de mensajes que imprime\n",
    "clf_1 = GridSearchCV(Bernoulli, parameters,cv=crossV, n_jobs=jobs, verbose=10)\n",
    "#entrenamos nuestro modelo\n",
    "clf_1.fit(Xtrain, trainY)\n",
    "#predecimos\n",
    "Ypred=clf_1.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1622068044708,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "9-MA4ZiAkRkY",
    "outputId": "9b22571f-d1b4-4dc4-bed8-1ce232d9100e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6055950840879689\n",
      "\n",
      "Precision: 0.6104989526432661\n",
      "\n",
      "Recall: 0.6055950840879689\n",
      "\n",
      "F-score: 0.607112929333288\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[6515 4024]\n",
      " [3293 4720]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64     10539\n",
      "           1       0.54      0.59      0.56      8013\n",
      "\n",
      "    accuracy                           0.61     18552\n",
      "   macro avg       0.60      0.60      0.60     18552\n",
      "weighted avg       0.61      0.61      0.61     18552\n",
      "\n",
      "\n",
      "\talpha: 0.98\n",
      "\n",
      "\tbinarize: 0.0\n",
      "\n",
      "\tclass_prior: None\n",
      "\n",
      "\tfit_prior: True\n",
      "\n",
      "\tforce_alpha: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\n'.format(accuracy_score(Ypred,testY)))\n",
    "print('Precision: {}\\n'.format(precision_score(Ypred,testY, average='weighted')))\n",
    "print('Recall: {}\\n'.format(recall_score(Ypred,testY, average='weighted')))\n",
    "print('F-score: {}\\n'.format(f1_score(Ypred,testY, average='weighted')))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "print(str(confusion_matrix(Ypred,testY)) + '\\n')\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(Ypred,testY) + '\\n')\n",
    "#obtenemos los mejores parametros\n",
    "best_parameters = clf_1.best_estimator_.get_params()\n",
    "for params in sorted(best_parameters.keys()):\n",
    "  print(\"\\t%s: %r\\n\" % (params, best_parameters[params]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gmxg2mu8CaI"
   },
   "source": [
    "Como podemos ver buscando entre nuestra grid de parámetros encontramos un parámetro que funcionó mejor para clasificar nuestros datos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IW1TQdvpoTMb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 5,\n",
       " 'error_score': nan,\n",
       " 'estimator__alpha': 1.0,\n",
       " 'estimator__binarize': 0.0,\n",
       " 'estimator__class_prior': None,\n",
       " 'estimator__fit_prior': True,\n",
       " 'estimator__force_alpha': True,\n",
       " 'estimator': BernoulliNB(),\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': {'alpha': [0.0,\n",
       "   0.01,\n",
       "   0.02,\n",
       "   0.03,\n",
       "   0.04,\n",
       "   0.05,\n",
       "   0.06,\n",
       "   0.07,\n",
       "   0.08,\n",
       "   0.09,\n",
       "   0.1,\n",
       "   0.11,\n",
       "   0.12,\n",
       "   0.13,\n",
       "   0.14,\n",
       "   0.15,\n",
       "   0.16,\n",
       "   0.17,\n",
       "   0.18,\n",
       "   0.19,\n",
       "   0.2,\n",
       "   0.21,\n",
       "   0.22,\n",
       "   0.23,\n",
       "   0.24,\n",
       "   0.25,\n",
       "   0.26,\n",
       "   0.27,\n",
       "   0.28,\n",
       "   0.29,\n",
       "   0.3,\n",
       "   0.31,\n",
       "   0.32,\n",
       "   0.33,\n",
       "   0.34,\n",
       "   0.35,\n",
       "   0.36,\n",
       "   0.37,\n",
       "   0.38,\n",
       "   0.39,\n",
       "   0.4,\n",
       "   0.41,\n",
       "   0.42,\n",
       "   0.43,\n",
       "   0.44,\n",
       "   0.45,\n",
       "   0.46,\n",
       "   0.47,\n",
       "   0.48,\n",
       "   0.49,\n",
       "   0.5,\n",
       "   0.51,\n",
       "   0.52,\n",
       "   0.53,\n",
       "   0.54,\n",
       "   0.55,\n",
       "   0.56,\n",
       "   0.57,\n",
       "   0.58,\n",
       "   0.59,\n",
       "   0.6,\n",
       "   0.61,\n",
       "   0.62,\n",
       "   0.63,\n",
       "   0.64,\n",
       "   0.65,\n",
       "   0.66,\n",
       "   0.67,\n",
       "   0.68,\n",
       "   0.69,\n",
       "   0.7,\n",
       "   0.71,\n",
       "   0.72,\n",
       "   0.73,\n",
       "   0.74,\n",
       "   0.75,\n",
       "   0.76,\n",
       "   0.77,\n",
       "   0.78,\n",
       "   0.79,\n",
       "   0.8,\n",
       "   0.81,\n",
       "   0.82,\n",
       "   0.83,\n",
       "   0.84,\n",
       "   0.85,\n",
       "   0.86,\n",
       "   0.87,\n",
       "   0.88,\n",
       "   0.89,\n",
       "   0.9,\n",
       "   0.91,\n",
       "   0.92,\n",
       "   0.93,\n",
       "   0.94,\n",
       "   0.95,\n",
       "   0.96,\n",
       "   0.97,\n",
       "   0.98,\n",
       "   0.99]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 10}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtenemos los parámetros que utilizamos en nuestro modelo\n",
    "clf_1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_4AtFhZZSSA"
   },
   "source": [
    "**RandomizedSearchCV**\n",
    "\n",
    "Búsqueda aleatoria de hiperparámetros.\n",
    "A diferencia de GridSearchCV, no se prueban todos los valores de los parámetros, sino que se muestrea un número fijo de configuraciones de parámetros a partir de las distribuciones especificadas. Tiene un parámetro adicional a GridSearchCV que es n_iter que especifica el número de iteraciones en búsqueda de los mejor hiperparametros dada una distribución.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10085,
     "status": "ok",
     "timestamp": 1622068076334,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "2DwsuMqPqss3",
    "outputId": "11680f9d-3b46-4435-f022-dc088856cf32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "nIter = 100\n",
    "#generamos una distribucion exponencial para nuestra alpha\n",
    "paramGrid = {'alpha': scipy.stats.expon(scale=1.0)}\n",
    "#generamos nuestro clasificador\n",
    "Bernoulli = BernoulliNB()\n",
    "#Generamos nuestro objeto RandomizedSearchCV\n",
    "clf_2 = RandomizedSearchCV(Bernoulli, paramGrid,n_iter=nIter,cv=crossV, n_jobs=jobs, verbose=10)\n",
    "#entrenamos el modelo\n",
    "clf_2.fit(Xtrain, trainY)\n",
    "#Predecimos\n",
    "Ypred=clf_2.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1622068079140,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "AtdcCM3HtG1h",
    "outputId": "c02e2442-77e1-4332-f152-ff3112dfe0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6097994825355757\n",
      "\n",
      "Precision: 0.6185791206901197\n",
      "\n",
      "Recall: 0.6097994825355757\n",
      "\n",
      "F-score: 0.6123016547803418\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[6707 4138]\n",
      " [3101 4606]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65     10845\n",
      "           1       0.53      0.60      0.56      7707\n",
      "\n",
      "    accuracy                           0.61     18552\n",
      "   macro avg       0.61      0.61      0.60     18552\n",
      "weighted avg       0.62      0.61      0.61     18552\n",
      "\n",
      "\n",
      "\talpha: 4.492271552091044\n",
      "\n",
      "\tbinarize: 0.0\n",
      "\n",
      "\tclass_prior: None\n",
      "\n",
      "\tfit_prior: True\n",
      "\n",
      "\tforce_alpha: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\n'.format(accuracy_score(Ypred,testY)))\n",
    "print('Precision: {}\\n'.format(precision_score(Ypred,testY, average='weighted')))\n",
    "print('Recall: {}\\n'.format(recall_score(Ypred,testY, average='weighted')))\n",
    "print('F-score: {}\\n'.format(f1_score(Ypred,testY, average='weighted')))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "print(str(confusion_matrix(Ypred,testY)) + '\\n')\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(Ypred,testY) + '\\n')\n",
    "best_parameters = clf_2.best_estimator_.get_params()\n",
    "for params in sorted(best_parameters.keys()):\n",
    "  print(\"\\t%s: %r\\n\" % (params, best_parameters[params]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHySD5WvuYzP"
   },
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8359,
     "status": "ok",
     "timestamp": 1622068293663,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "TP4oumoHzVUB",
    "outputId": "f889e25e-0fb6-4911-a892-2dffb42f062b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "paramGrid = {'alpha': scipy.stats.expon(scale=1.0)}\n",
    "Multinomial = MultinomialNB()\n",
    "clf_multi = RandomizedSearchCV(Multinomial, paramGrid,n_iter=nIter,cv=crossV, n_jobs=jobs, verbose=10)\n",
    "clf_multi.fit(Xtrain, trainY)\n",
    "Ypred=clf_multi.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1622068295557,
     "user": {
      "displayName": "obed ese",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0BAU0A8ikmmRS_YNpQ3BgNP0Lk03YQ-SkUpv4=s64",
      "userId": "01567877247348977530"
     },
     "user_tz": 300
    },
    "id": "Q4r11gBw0Biy",
    "outputId": "8ebaccc9-0617-4bef-de55-30f0dead466a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6092604570935748\n",
      "\n",
      "Precision: 0.6175003891246813\n",
      "\n",
      "Recall: 0.6092604570935748\n",
      "\n",
      "F-score: 0.6116295081646692\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[6683 4124]\n",
      " [3125 4620]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65     10807\n",
      "           1       0.53      0.60      0.56      7745\n",
      "\n",
      "    accuracy                           0.61     18552\n",
      "   macro avg       0.60      0.61      0.60     18552\n",
      "weighted avg       0.62      0.61      0.61     18552\n",
      "\n",
      "\n",
      "\talpha: 4.273306215209096\n",
      "\n",
      "\tclass_prior: None\n",
      "\n",
      "\tfit_prior: True\n",
      "\n",
      "\tforce_alpha: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\n'.format(accuracy_score(Ypred,testY)))\n",
    "print('Precision: {}\\n'.format(precision_score(Ypred,testY, average='weighted')))\n",
    "print('Recall: {}\\n'.format(recall_score(Ypred,testY, average='weighted')))\n",
    "print('F-score: {}\\n'.format(f1_score(Ypred,testY, average='weighted')))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "print(str(confusion_matrix(Ypred,testY)) + '\\n')\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(Ypred,testY) + '\\n')\n",
    "best_parameters = clf_multi.best_estimator_.get_params()\n",
    "for params in sorted(best_parameters.keys()):\n",
    "  print(\"\\t%s: %r\\n\" % (params, best_parameters[params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/cmendezc/miniconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/cmendezc/miniconda3/lib/python3.8/site-packages (from imbalanced-learn) (1.6.3)\n",
      "Collecting scikit-learn>=1.0.2 (from imbalanced-learn)\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.1.1 (from imbalanced-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/cmendezc/miniconda3/lib/python3.8/site-packages (from imbalanced-learn) (2.1.0)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0mm01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.0.1\n",
      "    Uninstalling joblib-1.0.1:\n",
      "      Successfully uninstalled joblib-1.0.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.2\n",
      "    Uninstalling scikit-learn-0.23.2:\n",
      "      Successfully uninstalled scikit-learn-0.23.2\n",
      "Successfully installed imbalanced-learn-0.12.4 joblib-1.4.2 scikit-learn-1.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914\n",
      "Counter({'Negative': 957, 'Positive': 957})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(Xtrain, trainY)\n",
    "print(len(y_resampled))\n",
    "counts = Counter(y_resampled)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "nIter = 100\n",
    "#generamos una distribucion exponencial para nuestra alpha\n",
    "paramGrid = {'alpha': scipy.stats.expon(scale=1.0)}\n",
    "#generamos nuestro clasificador\n",
    "Bernoulli = BernoulliNB()\n",
    "#Generamos nuestro objeto RandomizedSearchCV\n",
    "clf_under = RandomizedSearchCV(Bernoulli, paramGrid,n_iter=nIter,cv=crossV, n_jobs=jobs, verbose=10)\n",
    "#entrenamos el modelo\n",
    "clf_under.fit(X_resampled, y_resampled)\n",
    "#Predecimos\n",
    "Ypred=clf_under.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8637980085348507\n",
      "\n",
      "Precision: 0.8594994738834237\n",
      "\n",
      "Recall: 0.8637980085348507\n",
      "\n",
      "F-score: 0.8512513809061895\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "\n",
      "[[ 321  313]\n",
      " [  70 2108]]\n",
      "\n",
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.51      0.63       634\n",
      "    Positive       0.87      0.97      0.92      2178\n",
      "\n",
      "    accuracy                           0.86      2812\n",
      "   macro avg       0.85      0.74      0.77      2812\n",
      "weighted avg       0.86      0.86      0.85      2812\n",
      "\n",
      "\n",
      "\talpha: 3.1981502785952993\n",
      "\n",
      "\tbinarize: 0.0\n",
      "\n",
      "\tclass_prior: None\n",
      "\n",
      "\tfit_prior: True\n",
      "\n",
      "\tforce_alpha: 'warn'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}\\n'.format(accuracy_score(Ypred,testY)))\n",
    "print('Precision: {}\\n'.format(precision_score(Ypred,testY, average='weighted')))\n",
    "print('Recall: {}\\n'.format(recall_score(Ypred,testY, average='weighted')))\n",
    "print('F-score: {}\\n'.format(f1_score(Ypred,testY, average='weighted')))\n",
    "print('\\nConfusion matrix: \\n')\n",
    "print(str(confusion_matrix(Ypred,testY)) + '\\n')\n",
    "print('Classification report: \\n')\n",
    "print(classification_report(Ypred,testY) + '\\n')\n",
    "best_parameters = clf_under.best_estimator_.get_params()\n",
    "for params in sorted(best_parameters.keys()):\n",
    "  print(\"\\t%s: %r\\n\" % (params, best_parameters[params]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPQc+p0h8sDqYtjDS0AQYkK",
   "collapsed_sections": [],
   "name": "7Clasificación.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
